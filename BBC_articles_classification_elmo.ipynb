{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "BBC_articles_classification_elmo.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rickskyy/nlp-course/blob/master/BBC_articles_classification_elmo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bfbydnJhBtQ7",
        "colab_type": "text"
      },
      "source": [
        "# 1. Kernel Overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aLC4M55nBtQ-",
        "colab_type": "text"
      },
      "source": [
        "## 1.1 Defination :"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbR0eJN_BtRA",
        "colab_type": "text"
      },
      "source": [
        "In today world** Text Classification/Segmentation/Categorization** (for example ticket categorization in a call centre, email classification, logs category detection etc.) is a common task. With humongous data out there, its nearly impossible to do this manually. Let's try to solve this problem automatically using machine learning and natural language processing tools."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09E4F00iBtRC",
        "colab_type": "text"
      },
      "source": [
        "## 1.2 Problem Statement"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jRq-b9QBtRE",
        "colab_type": "text"
      },
      "source": [
        "BBC articles dataset (2126 records) consist of two features text and the assiciated categories namely \n",
        "1. Sport \n",
        "2. Business \n",
        "3. Politics \n",
        "4. Tech \n",
        "5. Others\n",
        "\n",
        "**Our task is to train a multiclass classification model on the mentioned dataset.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4uZW9O8BtRG",
        "colab_type": "text"
      },
      "source": [
        "## 1.3 Metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tM5fg591BtRI",
        "colab_type": "text"
      },
      "source": [
        "**Accuracy** - Classification accuracy is the number of correct predictions made as a\n",
        "ratio of all predictions made\n",
        "\n",
        "**Precision** - precision (also called positive predictive value) is the fraction of\n",
        "relevant instances among the retrieved instances\n",
        "\n",
        "**F1_score** - considers both the precision and the recall of the test to compute the\n",
        "score\n",
        "\n",
        "**Recall** – recall (also known as sensitivity) is the fraction of relevant instances that\n",
        "have been retrieved over the total amount of relevant instances\n",
        "\n",
        "**Why these metrics?** - We took Accuracy, Precision, F1 Score and Recall as metrics\n",
        "for evaluating our model because accuracy would give an estimate of correct prediction. Precision would give us an estimate about the positive category predicted value i.e. how much our model is giving relevant result. F1 Score gives a clubbed estimate of precision and recall.Recall would provide us the relevant positive category prediction to the false negative and true positive category recognition results."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7EAYxECNBtRK",
        "colab_type": "text"
      },
      "source": [
        "## 1.4 Machine Learning Model Considered:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcdGUSptBtRM",
        "colab_type": "text"
      },
      "source": [
        "We will be using **ELMO embeddings with KERAS** for this use case. \n",
        "\n",
        "ELMO and KERAS is not in the scope of this kernal. Kindly refer other external sources."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AemDJoSnBtRO",
        "colab_type": "text"
      },
      "source": [
        "# 2. Data Exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kRXRKaiOBtRQ",
        "colab_type": "text"
      },
      "source": [
        "### Step 2.1 Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnK33m3ICd36",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhruAz2YC2Vn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true,
        "id": "tZBbszFgBtRZ",
        "colab_type": "code",
        "outputId": "3df15b67-7a66-432e-cbdc-ec3e07c919de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "source": [
        "# change path to your copy of dataset\n",
        "data = pd.read_csv(r\"/content/drive/My Drive/bbc_articles/bbc-text.csv\", usecols=['category','text'])\n",
        "data.head(10)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tech</td>\n",
              "      <td>tv future in the hands of viewers with home th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>business</td>\n",
              "      <td>worldcom boss  left books alone  former worldc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sport</td>\n",
              "      <td>tigers wary of farrell  gamble  leicester say ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>sport</td>\n",
              "      <td>yeading face newcastle in fa cup premiership s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>entertainment</td>\n",
              "      <td>ocean s twelve raids box office ocean s twelve...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>politics</td>\n",
              "      <td>howard hits back at mongrel jibe michael howar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>politics</td>\n",
              "      <td>blair prepares to name poll date tony blair is...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>sport</td>\n",
              "      <td>henman hopes ended in dubai third seed tim hen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>sport</td>\n",
              "      <td>wilkinson fit to face edinburgh england captai...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>entertainment</td>\n",
              "      <td>last star wars  not for children  the sixth an...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        category                                               text\n",
              "0           tech  tv future in the hands of viewers with home th...\n",
              "1       business  worldcom boss  left books alone  former worldc...\n",
              "2          sport  tigers wary of farrell  gamble  leicester say ...\n",
              "3          sport  yeading face newcastle in fa cup premiership s...\n",
              "4  entertainment  ocean s twelve raids box office ocean s twelve...\n",
              "5       politics  howard hits back at mongrel jibe michael howar...\n",
              "6       politics  blair prepares to name poll date tony blair is...\n",
              "7          sport  henman hopes ended in dubai third seed tim hen...\n",
              "8          sport  wilkinson fit to face edinburgh england captai...\n",
              "9  entertainment  last star wars  not for children  the sixth an..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifDlLn4nBtRg",
        "colab_type": "text"
      },
      "source": [
        "# 3. Implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "6Jt4LLGsBtRi",
        "colab_type": "code",
        "outputId": "6bf8a75d-4126-4e24-c8ec-22c1ae6f3fe3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "from sklearn import metrics,preprocessing,model_selection\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import accuracy_score\n",
        "import keras\n",
        "from keras.layers import Input, Lambda, Dense\n",
        "from keras.models import Model\n",
        "import keras.backend as K\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import string\n",
        "import pandas as pd\n",
        "import re\n",
        "import spacy\n",
        "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
        "from spacy.lang.en import English\n",
        "\n",
        "spacy.load('en')\n",
        "parser = English()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.feature_extraction.stop_words module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.feature_extraction.text. Anything that cannot be imported from sklearn.feature_extraction.text is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l08wqQHHD08J",
        "colab_type": "code",
        "outputId": "377eeb27-a416-4665-c494-b160421e0bf6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Y2I28uqBtRn",
        "colab_type": "text"
      },
      "source": [
        "### Step 3.1 Label encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "G3LqfFN5BtRo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encode(le_enc, labels):\n",
        "    enc = le_enc.transform(labels)\n",
        "    return keras.utils.to_categorical(enc)\n",
        "\n",
        "def decode(le_enc, one_hot):\n",
        "    dec = np.argmax(one_hot, axis=1)\n",
        "    return le_enc.inverse_transform(dec)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Qevv4z_BtRs",
        "colab_type": "text"
      },
      "source": [
        "### Step 3.2 Data cleaning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "yK_pRU9ZBtRt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Stop words and special characters \n",
        "STOPLIST = set(stopwords.words('english') + list(ENGLISH_STOP_WORDS)) \n",
        "SYMBOLS = \" \".join(string.punctuation).split(\" \") + [\"-\", \"...\", \"”\", \"”\",\"''\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "UKm0sCXJBtRx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data Cleaner and tokenizer\n",
        "def tokenize_text(text):\n",
        "    \n",
        "    text = text.strip().replace(\"\\n\", \" \").replace(\"\\r\", \" \")\n",
        "    text = text.lower()\n",
        "    \n",
        "    tokens = parser(text)\n",
        "    \n",
        "    # lemmatization\n",
        "    tokens = [tok.lemma_.lower().strip() if tok.lemma_ != \"-PRON-\" else tok.lower_ for tok in tokens]\n",
        "    \n",
        "    # remove stop words and special charaters\n",
        "    tokens = filter(lambda tok: tok.lower() not in STOPLIST, tokens)\n",
        "    tokens = filter(lambda tok: tok not in SYMBOLS, tokens)\n",
        "    \n",
        "    # remove small words\n",
        "    tokens = filter(lambda tok: len(tok) >= 3, tokens)\n",
        "    \n",
        "    # remove remaining tokens that are not alphabetic\n",
        "    tokens = filter(lambda tok: tok.isalpha(), tokens)\n",
        "    \n",
        "    return ' '.join(list(set(tokens)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "DXu5Mdo8BtR1",
        "colab_type": "code",
        "outputId": "f569c71e-32e9-4c0c-8ce9-3b88d27c642d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "df = pd.DataFrame()\n",
        "df['text'] = data['text']\n",
        "df['text'] = df[\"text\"].apply(lambda x: tokenize_text(x))\n",
        "df['text'][0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'end advertise tim network suggest trend plasma enhance crystal service essentially big anybody liquid replay content possible forward abide theatre function display president good personalise grow instant keynote portable provider forget time different important tivotogo reflect live available ultimately guide worry issue deliver firm europe old launch senior talk hour tell today communication dvr radically push expert company brand directtv starcom record build business video recorder concern particularly hanlon technology engine box impact suit partnership challenge pcs market year future say connection gadget lose play microsoft las broadcaster digital telecom new uptake gather pause help example accord personal stacey announce showcase window website scheduler like gate producer bbc hard speech allow young tvs advert want tivo generation kind rewind recognise room add happen google book channel term press cable mediavest lack home vega high hume instead capability humax multimedia people jolna experience futurologist hand wind entertainment pvr broadcast comfortable free increase kid external search store consumer satellite japan broadband slow schedule ipod discuss commercial annual leaf way viewer set button use familiar putt know diaper promote watch reality lcd month model pre definition electronic programme device moment panel identity favourite loyalty vice mobile work chief carte revenue group pastime ces lead dvd news mean raise adam control choice simplify'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "YuaCNOc8BtR5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# add text classes\n",
        "df['class'] = data['category']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "b68StkS6BtR8",
        "colab_type": "code",
        "outputId": "7ac0ba73-70e6-452b-e4ef-5929ac07b261",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "# consider removing rare words\n",
        "# TODO use TF-IDF\n",
        "freq = pd.Series(' '.join(df['text']).split()).value_counts()[:4000]\n",
        "print(sum(freq))\n",
        "\n",
        "df['text'] = df['text'].apply(lambda x: \" \".join(x for x in x.split() if x in freq))\n",
        "df['text'] "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "237206\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       end advertise tim network suggest trend enhanc...\n",
              "1       david financial reply prosecutor bernie phone ...\n",
              "2       andy unknown way progress rugby head list engl...\n",
              "3       end boston charlton crystal saturday knock rep...\n",
              "4       andy major julia big hit knock december releas...\n",
              "                              ...                        \n",
              "2220    number healthy big december decent jump streng...\n",
              "2221    door worker immigration specific metropolitan ...\n",
              "2222    promise fantastic big summer customer air act ...\n",
              "2223    end escape solve need apparently suggest schoo...\n",
              "2224    victory end ball progress score want record ob...\n",
              "Name: text, Length: 2225, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvMdzfjiBtSA",
        "colab_type": "text"
      },
      "source": [
        "### Step 3.3 Data preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "bOgSDP3IBtSB",
        "colab_type": "code",
        "outputId": "2ef83600-1f73-4c7b-fedc-45b4c15d3fcb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Data preparation\n",
        "X = df['text'].tolist()\n",
        "y = df['class'].tolist()\n",
        "\n",
        "# Lebel encoding\n",
        "le_enc = preprocessing.LabelEncoder()\n",
        "le_enc.fit(y)\n",
        "\n",
        "y_en = encode(le_enc, y)\n",
        "y_en.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2225, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "zvIYXtmKBtSE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# split the dataset into training and testing datasets\n",
        "x_train, x_test, y_train, y_test = model_selection.train_test_split(np.asarray(X), np.asarray(y_en), test_size=0.2, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "slZyZkkYBtSH",
        "colab_type": "code",
        "outputId": "793fca4d-c22c-47a5-9cc6-c56b037b2f9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_train.shape\n",
        "y_train.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1780, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7A2vR7IyBtSL",
        "colab_type": "text"
      },
      "source": [
        "### Step 3.4 Build model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "_Vt036CqBtSQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# get elmo from tensorflow hub\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow as tf\n",
        "\n",
        "embed = hub.Module(\"https://tfhub.dev/google/elmo/3\", trainable=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "B34WomEqBtSU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ELMo Embedding\n",
        "def ELMoEmbedding(x):\n",
        "    return embed(tf.squeeze(tf.cast(x, tf.string)), signature=\"default\", as_dict=True)[\"default\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "X4v9s5ItBtSk",
        "colab_type": "code",
        "outputId": "f85f68aa-d2ab-4f76-f171-038262b83c8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "source": [
        "input_text = Input(shape=(1,), dtype=tf.string)\n",
        "embedding = Lambda(ELMoEmbedding, output_shape=(1024, ))(input_text)\n",
        "dense = Dense(256, activation='relu')(embedding)\n",
        "pred = Dense(5, activation='softmax')(dense)\n",
        "model = Model(inputs=[input_text], outputs=pred)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1x9Q-QCjEZSM",
        "colab_type": "code",
        "outputId": "2341b79f-8a7e-4030-ac57-af5c1e912da0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 581
        }
      },
      "source": [
        "with tf.Session() as session:\n",
        "    K.set_session(session)\n",
        "    session.run(tf.global_variables_initializer())  \n",
        "    session.run(tf.tables_initializer())\n",
        "    history = model.fit(x_train, y_train, epochs=1, batch_size=16)\n",
        "    model.save_weights('./elmo-model-v2.h5')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1780/1780 [==============================] - 3041s 2s/step - loss: 0.2806 - acc: 0.9124\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdHwSEkEEZkn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with tf.Session() as session:\n",
        "    K.set_session(session)\n",
        "    session.run(tf.global_variables_initializer())\n",
        "    session.run(tf.tables_initializer())\n",
        "    model.load_weights('./elmo-model-v2.h5')  \n",
        "    predicts = model.predict(x_test, batch_size=16)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AF6J3CYZBtSn",
        "colab_type": "text"
      },
      "source": [
        "# 4. Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N05nHtZacmPk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# decode test labels\n",
        "y_test = decode(le_enc, y_test)\n",
        "# decode predicted labels\n",
        "y_preds = decode(le_enc, predicts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "blsvHLvSBtSo",
        "colab_type": "code",
        "outputId": "0cb243de-652e-4c87-87d3-9e9bfd71f0fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "print(metrics.confusion_matrix(y_test, y_preds))\n",
        "\n",
        "print(metrics.classification_report(y_test, y_preds))\n",
        "\n",
        "print(\"Accuracy of ELMO is:\",accuracy_score(y_test,y_preds))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[91  1  7  0  2]\n",
            " [ 3 75  1  0  2]\n",
            " [ 0  0 83  0  0]\n",
            " [ 0  0  1 97  0]\n",
            " [ 4  5  0  1 72]]\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "     business       0.93      0.90      0.91       101\n",
            "entertainment       0.93      0.93      0.93        81\n",
            "     politics       0.90      1.00      0.95        83\n",
            "        sport       0.99      0.99      0.99        98\n",
            "         tech       0.95      0.88      0.91        82\n",
            "\n",
            "     accuracy                           0.94       445\n",
            "    macro avg       0.94      0.94      0.94       445\n",
            " weighted avg       0.94      0.94      0.94       445\n",
            "\n",
            "Accuracy of ELMO is: 0.9393258426966292\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHGVM8CmBtSr",
        "colab_type": "text"
      },
      "source": [
        "My result for 1 epoch is 93.93%. Better preprocessing is core to achieve higher accuracy.\n",
        "\n",
        "Best results found for the dataset is 97.77%.\n",
        "\n",
        "https://www.kaggle.com/sarthak221995/textclassification-97-77-accuracy-bert"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uKYQh5vLBtSu",
        "colab_type": "text"
      },
      "source": [
        "# 5. References"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kk9GH7ceBtSv",
        "colab_type": "text"
      },
      "source": [
        "> This kernel is based on the work of:\n",
        "\n",
        "> https://www.kaggle.com/sarthak221995/textclassification-95-5-accuracy-elmo/notebook\n",
        "> https://www.kaggle.com/saikumar587/text-classification-elmo/notebook"
      ]
    }
  ]
}